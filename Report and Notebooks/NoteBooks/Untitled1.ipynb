{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "963ea082",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navee\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59f5965175740a7a50ff3a4ed3e998f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\navee\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\navee\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0667a119a864ae6b96bb36b36c8112d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf86862114a45c6b99632aadaca5c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12faf47d1b6d4167b7147028dc362a5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80da4e9a6ed4f9b880eaab38ca5c27b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     26\u001b[0m     review \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReview\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 27\u001b[0m     scores_dict \u001b[38;5;241m=\u001b[39m polairty_scores_robert(review)\n\u001b[0;32m     28\u001b[0m     sentiment_results\u001b[38;5;241m.\u001b[39mappend(scores_dict)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Add sentiment analysis results to the DataFrame\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 17\u001b[0m, in \u001b[0;36mpolairty_scores_robert\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     15\u001b[0m scores \u001b[38;5;241m=\u001b[39m op[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     16\u001b[0m scores \u001b[38;5;241m=\u001b[39m softmax(scores)\n\u001b[1;32m---> 17\u001b[0m scores_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrobertneg\u001b[39m\u001b[38;5;124m'\u001b[39m: scores[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrobertnut\u001b[39m\u001b[38;5;124m'\u001b[39m: scores[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrobertnpos\u001b[39m\u001b[38;5;124m'\u001b[39m: scores[\u001b[38;5;241m2\u001b[39m]}\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scores_dict\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = 'roberta-base'\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Define a function to calculate polarity scores using RoBERTa\n",
    "def polairty_scores_robert(text):\n",
    "    encoded_text = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "    op = model(**encoded_text)\n",
    "    scores = op[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    scores_dict = {'robertneg': scores[0], 'robertnut': scores[1], 'robertnpos': scores[2]}\n",
    "    return scores_dict\n",
    "\n",
    "# Read the DataFrame\n",
    "df = pd.read_csv(\"flipkart_reviews.csv\")  # Provide the path to your dataset\n",
    "\n",
    "# Apply sentiment analysis to each row\n",
    "sentiment_results = []\n",
    "for index, row in df.iterrows():\n",
    "    review = row['Review']\n",
    "    scores_dict = polairty_scores_robert(review)\n",
    "    sentiment_results.append(scores_dict)\n",
    "\n",
    "# Add sentiment analysis results to the DataFrame\n",
    "sentiment_columns = ['robertneg', 'robertnut', 'robertnpos']\n",
    "sentiment_df = pd.DataFrame(sentiment_results, columns=sentiment_columns)\n",
    "df = pd.concat([df, sentiment_df], axis=1)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2aac708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"flipkart_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ca392e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My wife is so happy and best product üëåüèªüòò'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Review.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "209b44b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.48326042, 0.51673955], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df.Review.iloc[3]\n",
    "encoded_text = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "op = model(**encoded_text)\n",
    "scores = op[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc5d4ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Scores: {'robertneg': 0.0015707917045801878, 'robertnut': 0.007419607602059841, 'robertnpos': 0.9910095930099487}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5b2bdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8655868172645569, 0.12227807939052582, 0.012135038152337074]\n",
      "Sentiment Scores: {'robertneg': 0.8655868172645569, 'robertnut': 0.12227807939052582, 'robertnpos': 0.012135038152337074}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define a function to calculate sentiment scores using RoBERTa\n",
    "def calculate_sentiment_scores(text):\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "    # Forward pass through the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Apply softmax to get probabilities\n",
    "    probabilities = softmax(outputs.logits, axis=1).flatten().tolist()\n",
    "    print(probabilities)\n",
    "    # Return sentiment scores as a dictionary\n",
    "    scores_dict = {\n",
    "        'robertneg': probabilities[0],\n",
    "        'robertnut': probabilities[1],\n",
    "        'robertnpos': probabilities[2]\n",
    "    }\n",
    "    return scores_dict\n",
    "\n",
    "# Example usage:\n",
    "text = \"Very Bad\"\n",
    "sentiment_scores = calculate_sentiment_scores(text)\n",
    "print(\"Sentiment Scores:\", sentiment_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79c8de80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.002877665450796485, 0.03500713035464287, 0.9621151685714722]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "733b0f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Product_name  \\\n",
      "0     Lenovo Ideapad Gaming 3 Ryzen 5 Hexa Core 5600...   \n",
      "1     Lenovo Ideapad Gaming 3 Ryzen 5 Hexa Core 5600...   \n",
      "2     Lenovo Ideapad Gaming 3 Ryzen 5 Hexa Core 5600...   \n",
      "3     DELL Inspiron Athlon Dual Core 3050U - (4 GB/2...   \n",
      "4     DELL Inspiron Athlon Dual Core 3050U - (4 GB/2...   \n",
      "...                                                 ...   \n",
      "2299  MSI 27 inch Full HD IPS Panel Monitor (PRO MP2...   \n",
      "2300  MSI 27 inch Full HD IPS Panel Monitor (PRO MP2...   \n",
      "2301  MSI 27 inch Full HD IPS Panel Monitor (PRO MP2...   \n",
      "2302  MSI 27 inch Full HD IPS Panel Monitor (PRO MP2...   \n",
      "2303  MSI 27 inch Full HD IPS Panel Monitor (PRO MP2...   \n",
      "\n",
      "                                                 Review  Rating  robertneg  \\\n",
      "0     Best under 60k Great performanceI got it for a...       5   0.005346   \n",
      "1                                    Good perfomence...       5   0.005259   \n",
      "2     Great performance but usually it has also that...       5   0.077736   \n",
      "3              My wife is so happy and best product üëåüèªüòò       5   0.001227   \n",
      "4     Light weight laptop with new amazing features,...       5   0.001508   \n",
      "...                                                 ...     ...        ...   \n",
      "2299  Great display, accurate colours at this price ...       5   0.003550   \n",
      "2300  Superb monitor first brought 1 used for 2 mont...       5   0.010585   \n",
      "2301                                            Awesome       5   0.008338   \n",
      "2302                        Only one issue with adapter       5   0.520648   \n",
      "2303  Worth the money u spend for this monitor Great...       5   0.002878   \n",
      "\n",
      "      robertnut  robertnpos  \n",
      "0      0.041061    0.953593  \n",
      "1      0.135149    0.859592  \n",
      "2      0.282266    0.639997  \n",
      "3      0.006407    0.992366  \n",
      "4      0.010719    0.987773  \n",
      "...         ...         ...  \n",
      "2299   0.042456    0.953994  \n",
      "2300   0.626950    0.362466  \n",
      "2301   0.083822    0.907840  \n",
      "2302   0.456470    0.022883  \n",
      "2303   0.035007    0.962115  \n",
      "\n",
      "[2304 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "\n",
    "# Define a function to calculate sentiment scores using RoBERTa\n",
    "def calculate_sentiment_scores(text):\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "    # Forward pass through the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Apply softmax to get probabilities\n",
    "    probabilities = softmax(outputs.logits, axis=1).flatten().tolist()\n",
    "\n",
    "    # Return sentiment scores as a list\n",
    "    return probabilities\n",
    "\n",
    "# Apply sentiment analysis to each row in the DataFrame\n",
    "sentiment_scores_list = []\n",
    "for index, row in df.iterrows():\n",
    "    text = row['Review']\n",
    "    sentiment_scores = calculate_sentiment_scores(text)\n",
    "    sentiment_scores_list.append(sentiment_scores)\n",
    "\n",
    "# Add sentiment scores to the DataFrame\n",
    "sentiment_columns = ['robertneg', 'robertnut', 'robertnpos']\n",
    "sentiment_df = pd.DataFrame(sentiment_scores_list, columns=sentiment_columns)\n",
    "df = pd.concat([df, sentiment_df], axis=1)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92366a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>robertneg</th>\n",
       "      <th>robertnut</th>\n",
       "      <th>robertnpos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>0.476295</td>\n",
       "      <td>0.433912</td>\n",
       "      <td>0.089793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2</td>\n",
       "      <td>0.926307</td>\n",
       "      <td>0.065846</td>\n",
       "      <td>0.007847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>2</td>\n",
       "      <td>0.926307</td>\n",
       "      <td>0.065846</td>\n",
       "      <td>0.007847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>2</td>\n",
       "      <td>0.736681</td>\n",
       "      <td>0.233552</td>\n",
       "      <td>0.029767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>2</td>\n",
       "      <td>0.736681</td>\n",
       "      <td>0.233552</td>\n",
       "      <td>0.029767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>2</td>\n",
       "      <td>0.736681</td>\n",
       "      <td>0.233552</td>\n",
       "      <td>0.029767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>2</td>\n",
       "      <td>0.700588</td>\n",
       "      <td>0.272478</td>\n",
       "      <td>0.026935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>2</td>\n",
       "      <td>0.955419</td>\n",
       "      <td>0.040967</td>\n",
       "      <td>0.003614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>2</td>\n",
       "      <td>0.779997</td>\n",
       "      <td>0.209058</td>\n",
       "      <td>0.010945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>2</td>\n",
       "      <td>0.679641</td>\n",
       "      <td>0.249228</td>\n",
       "      <td>0.071131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>2</td>\n",
       "      <td>0.930067</td>\n",
       "      <td>0.065768</td>\n",
       "      <td>0.004164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>2</td>\n",
       "      <td>0.959442</td>\n",
       "      <td>0.036980</td>\n",
       "      <td>0.003578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>2</td>\n",
       "      <td>0.904015</td>\n",
       "      <td>0.087159</td>\n",
       "      <td>0.008826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>2</td>\n",
       "      <td>0.839433</td>\n",
       "      <td>0.149319</td>\n",
       "      <td>0.011248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>2</td>\n",
       "      <td>0.959442</td>\n",
       "      <td>0.036980</td>\n",
       "      <td>0.003578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>2</td>\n",
       "      <td>0.904015</td>\n",
       "      <td>0.087159</td>\n",
       "      <td>0.008826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>2</td>\n",
       "      <td>0.904015</td>\n",
       "      <td>0.087159</td>\n",
       "      <td>0.008826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>2</td>\n",
       "      <td>0.959442</td>\n",
       "      <td>0.036980</td>\n",
       "      <td>0.003578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>2</td>\n",
       "      <td>0.839433</td>\n",
       "      <td>0.149319</td>\n",
       "      <td>0.011248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1411</th>\n",
       "      <td>2</td>\n",
       "      <td>0.839433</td>\n",
       "      <td>0.149319</td>\n",
       "      <td>0.011248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>2</td>\n",
       "      <td>0.839433</td>\n",
       "      <td>0.149319</td>\n",
       "      <td>0.011248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>2</td>\n",
       "      <td>0.926307</td>\n",
       "      <td>0.065846</td>\n",
       "      <td>0.007847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>2</td>\n",
       "      <td>0.926307</td>\n",
       "      <td>0.065846</td>\n",
       "      <td>0.007847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>2</td>\n",
       "      <td>0.388020</td>\n",
       "      <td>0.402135</td>\n",
       "      <td>0.209845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712</th>\n",
       "      <td>2</td>\n",
       "      <td>0.388020</td>\n",
       "      <td>0.402135</td>\n",
       "      <td>0.209845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>2</td>\n",
       "      <td>0.609498</td>\n",
       "      <td>0.307234</td>\n",
       "      <td>0.083267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>2</td>\n",
       "      <td>0.609498</td>\n",
       "      <td>0.307234</td>\n",
       "      <td>0.083267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>2</td>\n",
       "      <td>0.652015</td>\n",
       "      <td>0.286969</td>\n",
       "      <td>0.061016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>2</td>\n",
       "      <td>0.652015</td>\n",
       "      <td>0.286969</td>\n",
       "      <td>0.061016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>2</td>\n",
       "      <td>0.070781</td>\n",
       "      <td>0.471924</td>\n",
       "      <td>0.457295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>2</td>\n",
       "      <td>0.451825</td>\n",
       "      <td>0.452481</td>\n",
       "      <td>0.095694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>2</td>\n",
       "      <td>0.366086</td>\n",
       "      <td>0.498954</td>\n",
       "      <td>0.134960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>2</td>\n",
       "      <td>0.592700</td>\n",
       "      <td>0.367039</td>\n",
       "      <td>0.040261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>2</td>\n",
       "      <td>0.979488</td>\n",
       "      <td>0.017796</td>\n",
       "      <td>0.002716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>2</td>\n",
       "      <td>0.178203</td>\n",
       "      <td>0.445731</td>\n",
       "      <td>0.376065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>2</td>\n",
       "      <td>0.817404</td>\n",
       "      <td>0.163941</td>\n",
       "      <td>0.018655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>2</td>\n",
       "      <td>0.592700</td>\n",
       "      <td>0.367039</td>\n",
       "      <td>0.040261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2082</th>\n",
       "      <td>2</td>\n",
       "      <td>0.979488</td>\n",
       "      <td>0.017796</td>\n",
       "      <td>0.002716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>2</td>\n",
       "      <td>0.178203</td>\n",
       "      <td>0.445731</td>\n",
       "      <td>0.376065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>2</td>\n",
       "      <td>0.488748</td>\n",
       "      <td>0.349605</td>\n",
       "      <td>0.161647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2174</th>\n",
       "      <td>2</td>\n",
       "      <td>0.968034</td>\n",
       "      <td>0.029014</td>\n",
       "      <td>0.002953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2176</th>\n",
       "      <td>2</td>\n",
       "      <td>0.864312</td>\n",
       "      <td>0.124889</td>\n",
       "      <td>0.010800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>2</td>\n",
       "      <td>0.047380</td>\n",
       "      <td>0.902605</td>\n",
       "      <td>0.050015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2212</th>\n",
       "      <td>2</td>\n",
       "      <td>0.047380</td>\n",
       "      <td>0.902605</td>\n",
       "      <td>0.050015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>2</td>\n",
       "      <td>0.047380</td>\n",
       "      <td>0.902605</td>\n",
       "      <td>0.050015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>2</td>\n",
       "      <td>0.812705</td>\n",
       "      <td>0.154843</td>\n",
       "      <td>0.032453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Rating  robertneg  robertnut  robertnpos\n",
       "13         2   0.476295   0.433912    0.089793\n",
       "183        2   0.926307   0.065846    0.007847\n",
       "203        2   0.926307   0.065846    0.007847\n",
       "689        2   0.736681   0.233552    0.029767\n",
       "769        2   0.736681   0.233552    0.029767\n",
       "799        2   0.736681   0.233552    0.029767\n",
       "860        2   0.700588   0.272478    0.026935\n",
       "974        2   0.955419   0.040967    0.003614\n",
       "1030       2   0.779997   0.209058    0.010945\n",
       "1046       2   0.679641   0.249228    0.071131\n",
       "1051       2   0.930067   0.065768    0.004164\n",
       "1136       2   0.959442   0.036980    0.003578\n",
       "1143       2   0.904015   0.087159    0.008826\n",
       "1157       2   0.839433   0.149319    0.011248\n",
       "1163       2   0.959442   0.036980    0.003578\n",
       "1240       2   0.904015   0.087159    0.008826\n",
       "1249       2   0.904015   0.087159    0.008826\n",
       "1299       2   0.959442   0.036980    0.003578\n",
       "1381       2   0.839433   0.149319    0.011248\n",
       "1411       2   0.839433   0.149319    0.011248\n",
       "1431       2   0.839433   0.149319    0.011248\n",
       "1472       2   0.926307   0.065846    0.007847\n",
       "1502       2   0.926307   0.065846    0.007847\n",
       "1702       2   0.388020   0.402135    0.209845\n",
       "1712       2   0.388020   0.402135    0.209845\n",
       "1723       2   0.609498   0.307234    0.083267\n",
       "1733       2   0.609498   0.307234    0.083267\n",
       "1790       2   0.652015   0.286969    0.061016\n",
       "1800       2   0.652015   0.286969    0.061016\n",
       "1833       2   0.070781   0.471924    0.457295\n",
       "1954       2   0.451825   0.452481    0.095694\n",
       "1987       2   0.366086   0.498954    0.134960\n",
       "2001       2   0.592700   0.367039    0.040261\n",
       "2002       2   0.979488   0.017796    0.002716\n",
       "2006       2   0.178203   0.445731    0.376065\n",
       "2052       2   0.817404   0.163941    0.018655\n",
       "2081       2   0.592700   0.367039    0.040261\n",
       "2082       2   0.979488   0.017796    0.002716\n",
       "2086       2   0.178203   0.445731    0.376065\n",
       "2140       2   0.488748   0.349605    0.161647\n",
       "2174       2   0.968034   0.029014    0.002953\n",
       "2176       2   0.864312   0.124889    0.010800\n",
       "2196       2   0.047380   0.902605    0.050015\n",
       "2212       2   0.047380   0.902605    0.050015\n",
       "2273       2   0.047380   0.902605    0.050015\n",
       "2297       2   0.812705   0.154843    0.032453"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two[df.columns[-4:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ab4446d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>robertneg</th>\n",
       "      <th>robertnut</th>\n",
       "      <th>robertnpos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005346</td>\n",
       "      <td>0.041061</td>\n",
       "      <td>0.953593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005259</td>\n",
       "      <td>0.135149</td>\n",
       "      <td>0.859592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.077736</td>\n",
       "      <td>0.282266</td>\n",
       "      <td>0.639997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.006407</td>\n",
       "      <td>0.992366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.010719</td>\n",
       "      <td>0.987773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating  robertneg  robertnut  robertnpos\n",
       "0       5   0.005346   0.041061    0.953593\n",
       "1       5   0.005259   0.135149    0.859592\n",
       "2       5   0.077736   0.282266    0.639997\n",
       "3       5   0.001227   0.006407    0.992366\n",
       "4       5   0.001508   0.010719    0.987773"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d49734f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>robertneg</th>\n",
       "      <th>robertnut</th>\n",
       "      <th>robertnpos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005346</td>\n",
       "      <td>0.041061</td>\n",
       "      <td>0.953593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005259</td>\n",
       "      <td>0.135149</td>\n",
       "      <td>0.859592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.077736</td>\n",
       "      <td>0.282266</td>\n",
       "      <td>0.639997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.006407</td>\n",
       "      <td>0.992366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.010719</td>\n",
       "      <td>0.987773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating  robertneg  robertnut  robertnpos\n",
       "0       5   0.005346   0.041061    0.953593\n",
       "1       5   0.005259   0.135149    0.859592\n",
       "2       5   0.077736   0.282266    0.639997\n",
       "3       5   0.001227   0.006407    0.992366\n",
       "4       5   0.001508   0.010719    0.987773"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.columns[-4:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4ae7308",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating 1:\n",
      "Negative Threshold: 0.7804764147858014\n",
      "Neutral Threshold: 0.16784208274001014\n",
      "Positive Threshold: 0.05168150020282432\n",
      "\n",
      "Rating 2:\n",
      "Negative Threshold: 0.6775490829478139\n",
      "Neutral Threshold: 0.2567918043502647\n",
      "Positive Threshold: 0.06565912479393023\n",
      "\n",
      "Rating 3:\n",
      "Negative Threshold: 0.2561798040073232\n",
      "Neutral Threshold: 0.2085956098312246\n",
      "Positive Threshold: 0.53522458443019\n",
      "\n",
      "Rating 4:\n",
      "Negative Threshold: 0.07231745697883551\n",
      "Neutral Threshold: 0.16061943494697925\n",
      "Positive Threshold: 0.7670631085765427\n",
      "\n",
      "Rating 5:\n",
      "Negative Threshold: 0.020599798396413044\n",
      "Neutral Threshold: 0.10060444753549659\n",
      "Positive Threshold: 0.8787957529837936\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize thresholds for each sentiment class\n",
    "neg_thresholds = []\n",
    "nut_thresholds = []\n",
    "pos_thresholds = []\n",
    "\n",
    "# Calculate thresholds for each rating\n",
    "for rating in range(1, 6):\n",
    "    rating_data = df[df['Rating'] == rating]\n",
    "    neg_threshold = rating_data['robertneg'].mean()\n",
    "    nut_threshold = rating_data['robertnut'].mean()\n",
    "    pos_threshold = rating_data['robertnpos'].mean()\n",
    "    neg_thresholds.append(neg_threshold)\n",
    "    nut_thresholds.append(nut_threshold)\n",
    "    pos_thresholds.append(pos_threshold)\n",
    "\n",
    "# Print thresholds for each sentiment class and rating\n",
    "for rating in range(1, 6):\n",
    "    print(f\"Rating {rating}:\")\n",
    "    print(f\"Negative Threshold: {neg_thresholds[rating-1]}\")\n",
    "    print(f\"Neutral Threshold: {nut_thresholds[rating-1]}\")\n",
    "    print(f\"Positive Threshold: {pos_thresholds[rating-1]}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d892135",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_columns = ['robertneg', 'robertnut', 'robertnpos']\n",
    "# sentiment_df = pd.DataFrame(sentiment_scores_list, columns=sentiment_columns)\n",
    "df = pd.concat([df, sentiment_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d5475a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>robertneg</th>\n",
       "      <th>robertnut</th>\n",
       "      <th>robertnpos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005346</td>\n",
       "      <td>0.041061</td>\n",
       "      <td>0.953593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005259</td>\n",
       "      <td>0.135149</td>\n",
       "      <td>0.859592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077736</td>\n",
       "      <td>0.282266</td>\n",
       "      <td>0.639997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001227</td>\n",
       "      <td>0.006407</td>\n",
       "      <td>0.992366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.010719</td>\n",
       "      <td>0.987773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>0.003550</td>\n",
       "      <td>0.042456</td>\n",
       "      <td>0.953994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>0.010585</td>\n",
       "      <td>0.626950</td>\n",
       "      <td>0.362466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2301</th>\n",
       "      <td>0.008338</td>\n",
       "      <td>0.083822</td>\n",
       "      <td>0.907840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2302</th>\n",
       "      <td>0.520648</td>\n",
       "      <td>0.456470</td>\n",
       "      <td>0.022883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2303</th>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.035007</td>\n",
       "      <td>0.962115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2304 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      robertneg  robertnut  robertnpos\n",
       "0      0.005346   0.041061    0.953593\n",
       "1      0.005259   0.135149    0.859592\n",
       "2      0.077736   0.282266    0.639997\n",
       "3      0.001227   0.006407    0.992366\n",
       "4      0.001508   0.010719    0.987773\n",
       "...         ...        ...         ...\n",
       "2299   0.003550   0.042456    0.953994\n",
       "2300   0.010585   0.626950    0.362466\n",
       "2301   0.008338   0.083822    0.907840\n",
       "2302   0.520648   0.456470    0.022883\n",
       "2303   0.002878   0.035007    0.962115\n",
       "\n",
       "[2304 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.columns[-3:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dda1f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('roberta.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
